{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NAMA: Zanuar Rikza Aditiya**  \n",
    "**NIM: 230411100087**  \n",
    "**MATA KULIAH: EKSTRAKSI INFORMASI A**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Code ini dugunakan untuk mengambil URL halaman detail setiap putusan dari list putusan  \n",
    "parameter yang disiapkan adalah URL posisi awal munculnya list putusan sesuai kriteria yang akan di ambil dan URL halaman terakhir yang memuat list putusan  \n",
    "output dari code ini adalah file dengan nama hasilListURLPage.txt yang berisi list URL untuk melihat detail setiap putusan  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "from bs4 import BeautifulSoup    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**fungsi getURLfromWeb untuk Mendapatkan url putusan dari website**  \n",
    "Penjelasan lainya berada pada komentar code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getURLfromWeb(url):\n",
    "\n",
    "    response = requests.get(url, verify=False)\n",
    "    print(response)\n",
    "\n",
    "    htmlCode1 = BeautifulSoup(response.text, 'html.parser')\n",
    "    result1=htmlCode1.findAll('a')\n",
    "    \n",
    "    urlHasil=[]\n",
    "    for eachResult1 in result1:    \n",
    "        cariURLawal=str(eachResult1).find('https://putusan3.mahkamahagung.go.id/direktori/putusan/')\n",
    "        cariURLakhir=str(eachResult1).find('html\">Putusan') + 4\n",
    "        #print(cariURLakhir)\n",
    "        if cariURLawal == 9 and cariURLakhir >= 4:\n",
    "            #print(str(eachResult1)[cariURLawal:cariURLakhir])\n",
    "            cariURL=str(eachResult1)[cariURLawal:cariURLakhir]\n",
    "            urlHasil.append(cariURL)\n",
    "\n",
    "    print(urlHasil)\n",
    "    return(urlHasil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Penjelasan lainya berada pada komentar code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    data_path = \"./data/\"\n",
    "    #url1 = 'https://putusan3.mahkamahagung.go.id/direktori/kategori/jenis/pencurian-1.html'\n",
    "    #url2 = 'https://putusan3.mahkamahagung.go.id/direktori/kategori/jenis/pencurian-1/page/'\n",
    "    \n",
    "    url1 = 'https://putusan3.mahkamahagung.go.id/direktori/index/pengadilan/pn-pekalongan/kategori/pidana-umum-1.html'\n",
    "    url2 = 'https://putusan3.mahkamahagung.go.id/direktori/index/pengadilan/pn-pekalongan/kategori/pidana-umum-1/page/'\n",
    "    \n",
    "    listHasil = []\n",
    "    # Saya ingin mengambil putusan hingga page 50\n",
    "    ulang = 50\n",
    "\n",
    "    # Saya menambahkan last index \n",
    "    # agar saat code gagal karena suatu alasan saya tidak mengulangi lagi dari awal\n",
    "    if not os.path.exists(data_path + \"lastindex.txt\"):\n",
    "        with open(data_path + \"lastindex.txt\", \"w\", encoding=\"UTF-8\") as file_index:\n",
    "            file_index.write(str(19))\n",
    "    try:\n",
    "        last_index = int(open(\"./data/lastindex.txt\", \"r\", encoding=\"UTF-8\").read())\n",
    "    except:\n",
    "        last_index = 19\n",
    "\n",
    "    startTime = time.time()\n",
    "\n",
    "    # file_hasil = open(data_path + \"hasilListURLPage.txt\", \"w\", encoding='UTF8')\n",
    "    \n",
    "    # Scraping di mulai dari index terakhir yang telah di cek + 1\n",
    "    for i in range(last_index, ulang):\n",
    "        if i == 0:\n",
    "            url = url1\n",
    "            print(1)\n",
    "        else:            \n",
    "            n=i+1\n",
    "            url = url2+str(n)+'.html'\n",
    "            print(2)   \n",
    "\n",
    "        listHasil = getURLfromWeb(url)\n",
    "\n",
    "        print(listHasil)\n",
    "\n",
    "        # menambahkan list url ke file hasilListURLPage.txt\n",
    "        # agar jika gagal tidak berulang dari awal\n",
    "        with open(data_path + \"hasilListURLPage.txt\", \"a\", encoding=\"UTF-8\") as file_hasil: \n",
    "            for listURL in listHasil:\n",
    "                file_hasil.write(listURL+\"\\n\")\n",
    "        \n",
    "        print(last_index)\n",
    "        # Menyimpan index terakhir yang telah di cek + 1 \n",
    "        # agar kita tahu dari mana kita harus mulai lagi tanpa mengulangi dari awal\n",
    "        with open(data_path + \"lastindex.txt\", \"w\", encoding=\"UTF-8\") as file_index:\n",
    "            file_index.write(str(i + 1))\n",
    "\n",
    "    # file_hasil.close()\n",
    "    endTime = time.time()\n",
    "    print(listHasil)\n",
    "    print('Time Processing : ', endTime-startTime, ' Second')\n",
    "        \n",
    "main();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EKSTRAK META INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import csv\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**fungsi generateFileCvs untuk menyimpan data yang di dapatkan dari ektraksi informasi**  \n",
    "Penjelasan lain nya berupa komentar di code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateFileCSV(listHasil,csvName1):\n",
    "\n",
    "\tcsvFolrder = \"./data/\"\n",
    "\tcsvName = csvName1\n",
    "\n",
    "\t# Mengecek apkah file csv ada atau tidak\n",
    "\t# jika ada akan membuka file dengan mode 'a' untuk menambahkan data\n",
    "\t# jika tidak akan membuka file dengan mode 'w' untuk membuat baru file nya\n",
    "\t# dengan kolom kolom yang di tentukan\n",
    "\tif os.path.exists(csvName):\n",
    "\n",
    "\t\tf = open(csvName, 'a', newline='\\n')\n",
    "\t\tprint(f)\n",
    "\t\tprint(\"ada\")\n",
    "\t\tw = csv.writer(f)\n",
    "\n",
    "\telse:\n",
    "\n",
    "\t\tf = open(csvName, 'w', newline='\\n')\n",
    "\t\tprint(f)\n",
    "\t\tprint(\"tidak ada\")\n",
    "\n",
    "\t\tw = csv.writer(f)\n",
    "\t\tw.writerow((\"terdakwa\", \"penuntut_umum\", \"nomor\", \"tingkat_proses\", \"klasifikasi\", \"kata_kunci\", \"tahun\", \"tanggal_register\",\n",
    "              \"lembaga_peradilan\", \"jenis_lembaga_peradilan\", \"hakim_ketua\", \"hakim_anggota\", \"panitera\", \"amar\",\n",
    "              \"amar_lainnya\", \"catatan_amar\", \"tanggal_musyawarah\", \"tanggal_dibacakan\", \"kaidah\", \"abstrak\", \"url\"))\n",
    "\n",
    "\t# menulis file csv\n",
    "\tprint(listHasil)\n",
    "\tfor s in listHasil:\n",
    "\t\tw.writerow(s)\n",
    "\n",
    "\tf.close()\n",
    "\tberhasil = \"\\nCreate Csv file Berhasil\\n\"\n",
    "\treturn berhasil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**fungsi generateMeta untuk mengekstraksi informasi penting dari**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateMeta(urlMeta):\n",
    "\n",
    "    url = str(urlMeta).strip()\n",
    "    # url = 'https://putusan3.mahkamahagung.go.id/direktori/putusan/zaedca28e81ec25e8cb4313634373336.html'\n",
    "    response = requests.get(url, verify=False)\n",
    "    # print(url)\n",
    "    print(response)\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    cleanTags = re.compile('<.*?>')\n",
    "\n",
    "    listMetaHead = [\"terdakwa\", \"penuntut_umum\", \"nomor\", \"tingkat_proses\", \"klasifikasi\", \"kata_kunci\", \"tahun\", \"tanggal_register\",\n",
    "              \"lembaga_peradilan\", \"jenis_lembaga_peradilan\", \"hakim_ketua\", \"hakim_anggota\", \"panitera\", \"amar\",\n",
    "              \"amar_lainnya\", \"catatan_amar\", \"tanggal_musyawarah\", \"tanggal_dibacakan\", \"kaidah\", \"abstrak\", \"url\"]\n",
    "\n",
    "    # initialisasi\n",
    "    listMeta = []\n",
    "    \n",
    "    # for i in range(len(listMetaHead)):\n",
    "        #listMeta.append(\"\")\n",
    "\n",
    "    rowsMETA1 = soup.find(\"ul\", {\"class\": \"portfolio-meta nobottommargin\"}).find(\"table\").findAll(\"tr\")\n",
    "    rowsMETA2 = soup.findAll(\"ul\", {\"class\": \"portfolio-meta nobottommargin\"})\n",
    "\n",
    "    #print('-------------------------')\n",
    "    for row in rowsMETA1:\n",
    "        coll = row.findAll(\"td\")\n",
    "\n",
    "        cleantext2 =''\n",
    "        cleantext1 =''\n",
    "\n",
    "        if len(coll) > 1:\n",
    "            cleantext2 = (re.sub(cleanTags, '', str(coll[1]))).strip()\n",
    "            listMeta.append(cleantext2.replace('\\n',' '))\n",
    "            #print(cleantext2.replace('\\n',' '))\n",
    "\n",
    "        else:\n",
    "            cleantext1 = (re.sub(cleanTags, ' ', str(coll[0]))).strip()\n",
    "            # untuk putusan pidana akan muncul terdakwa dan penuntut umum pada meta\n",
    "            # sedangkan untuk putusan selain pidana tidak muncul\n",
    "\n",
    "            pidorpdt = re.search( r'(.*)/Pdt.(.*)',str(cleantext1), re.M|re.I)\n",
    "\n",
    "            # check dokumen putusannya pidana atau perdata\n",
    "            if pidorpdt == None:\n",
    "                entTerdakwah = re.search( r'(.*)Terdakwa:(.*)',str(cleantext1), re.M|re.I)\n",
    "                entPenuntut = re.search( r'Penuntut Umum:(.*)Terdakwa:',str(cleantext1), re.M|re.I)\n",
    "            else:\n",
    "                entTerdakwah = re.search( r'(.*)Tergugat:(.*)',str(cleantext1), re.M|re.I)\n",
    "                entPenuntut = re.search( r'Penggugat:(.*)Tergugat:',str(cleantext1), re.M|re.I)\n",
    "\n",
    "            if entTerdakwah == None:\n",
    "                listMeta.append(\"\")\n",
    "            else:\n",
    "                listMeta.append(entTerdakwah.group(2))\n",
    "\n",
    "            if entPenuntut == None:\n",
    "                listMeta.append(\"\")\n",
    "            else:\n",
    "                listMeta.append(entPenuntut.group(1))\n",
    "\n",
    "            #print(coll[0])\n",
    "            #print(entTerdakwah.group(2))\n",
    "            #print(entPenuntut.group(1))\n",
    "\n",
    "    urlDL = rowsMETA2[1].findAll(\"li\")\n",
    "    urlDLStr = str(urlDL[4])\n",
    "    listMeta.append(urlDLStr[urlDLStr.find(\"https\"):urlDLStr.find('\">')])\n",
    "    #print(urlDLStr[urlDLStr.find(\"https\"):urlDLStr.find('\">')])\n",
    "    #print(listMeta)\n",
    "\n",
    "    return listMeta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**fungsi main menjalankan fungsi fungsi sebelumnya**  \n",
    "Penjelasan lainya berada pada komentar code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "    # folderListURL = pathFile\n",
    "    data_path = \"./data/\"\n",
    "    fileListURL = \"./data/hasilListURLPage.txt\"\n",
    "    fileMetaCSV = \"./data/metaPidanaUmum.csv\"\n",
    "\n",
    "    # Saya menambahkan last index \n",
    "    # agar saat code gagal karena suatu alasan saya tidak perlu menghitung \n",
    "    # jumlah data yang terkumpul secara manual dan juga agar tidak salah hitung\n",
    "    # karena sudah dihitung oleh program\n",
    "    if not os.path.exists(data_path + \"lastindexmeta.txt\"):\n",
    "        with open(data_path + \"lastindexmeta.txt\", \"w\", encoding=\"UTF-8\") as file_index:\n",
    "            file_index.write(str(0))\n",
    "            \n",
    "    try:\n",
    "        last_index = int(open(data_path + \"lastindexmeta.txt\", \"r\", encoding=\"UTF-8\").read())\n",
    "    except:\n",
    "        last_index = 0\n",
    "\n",
    "    startTime = time.time()\n",
    "    openfileListURL = open(fileListURL, \"r\", encoding='UTF8')\n",
    "    bacaListURL = openfileListURL.readlines()\n",
    "    openfileListURL.close()\n",
    "\n",
    "    i = 1\n",
    "\n",
    "    # Melakukan Perulangan dari index terakhir yang dicek + 1 samapi\n",
    "    for index in range(last_index, len(bacaListURL)):\n",
    "        try:\n",
    "            #print(str(barisURL))\n",
    "            print(bacaListURL[last_index])\n",
    "            # membungkus hasil generate meta ke dalam list \n",
    "            # karena fungsi generateFileCsv mengolah list dalam list untuk menambahkan data\n",
    "            hasil = [generateMeta(str(bacaListURL[index]))]\n",
    "            print(\"======= ROW HASIL =======\",i)\n",
    "            # Langsung menulis hasil yang ditemukan agar tidak diulangi dari awal saat gagal\n",
    "            createFile = generateFileCSV(hasil, fileMetaCSV)\n",
    "        except Exception as e:\n",
    "            print(f\"Error Get Meta Inf, {e}\")\n",
    "        \n",
    "        # Menyimpan index terakhir yang telah di cek + 1 \n",
    "        # agar kita tahu dari mana kita dapat mulai lagi mengekstrak infromasi\n",
    "        with open(data_path + \"lastindexmeta.txt\", \"w\", encoding=\"UTF-8\") as file_index:\n",
    "            file_index.write(str(index + 1))\n",
    "\n",
    "        i=i+1\n",
    "    \n",
    "    endTime = time.time()\n",
    "    # print(listHasil)\n",
    "    print('Time Processing : ', endTime-startTime, ' Second')\n",
    "\n",
    "main();\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
